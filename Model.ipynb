{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.model_selection import KFold\n",
    "# from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from model_zoo import my_lgb,my_xgb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评分函数与提交函数\n",
    "def score(pre, truth):\n",
    "    return 1 / (MAE(pre, truth) + 1)\n",
    "\n",
    "def MAE(pre, truth):\n",
    "    return abs((np.rint(pre) - truth)).mean()\n",
    "\n",
    "def submit(model_name='default', predictions=None):\n",
    "    sub_df = pd.read_csv('dataset/submit_example.csv')\n",
    "    sub_df[' score'] = np.rint(predictions).astype(int)\n",
    "    sub_df.to_csv(\"output/{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train_dataset.csv')\n",
    "test_df = pd.read_csv('dataset/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征工程，简单粗暴。\n",
    "\n",
    "* 长尾数据处理\n",
    "\n",
    "* 过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(df, feature):\n",
    "    for f in feature:\n",
    "        data[f] = np.rint(data[f])\n",
    "        new_feature = f + '_count'\n",
    "        tmp = df.groupby(f).size().reset_index().rename(columns={0:new_feature})\n",
    "        #  tmp[new_feature] = tmp[new_feature].cumsum()*100/df.shape[0]\n",
    "        df = df.merge(tmp, 'left', on = f)\n",
    "    return df\n",
    "    \n",
    "def generate_feature(df):\n",
    "    df['用户前五个月平均消费值（元）'] = (df['用户近6个月平均消费值（元）']*6 - df['用户账单当月总费用（元）'])/5\n",
    "    df['当月消费值较前五个月平均消费值'] = df['用户账单当月总费用（元）'] - df['用户前五个月平均消费值（元）']\n",
    "    app_col = ['当月视频播放类应用使用次数','当月金融理财类应用使用总次数','当月网购类应用使用次数']\n",
    "    df['是否使用网购类应用'] = np.where(df['当月网购类应用使用次数'] > 0, 1, 0)\n",
    "    df['当月网购类应用使用次数' + '百分比'] = (df['当月网购类应用使用次数'])/(df[app_col].sum(axis=1) + 1e-8)\n",
    "    df.loc[df['用户年龄']==0, '用户年龄'] = df['用户年龄'].mode()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 长尾数据\n",
    "long_tail = ['当月视频播放类应用使用次数', '当月金融理财类应用使用总次数','当月网购类应用使用次数',\n",
    "             '缴费用户最近一次缴费金额（元）','用户当月账户余额（元）', '用户账单当月总费用（元）',\n",
    "             '用户近6个月平均消费值（元）','当月通话交往圈人数'] \n",
    "#  '缴费用户最近一次缴费金额（元）',\n",
    "df = percent(df, long_tail)\n",
    "df['当月视频播放类应用使用次数'] = np.where(df['当月视频播放类应用使用次数']>30000, 30000, df['当月视频播放类应用使用次数'])\n",
    "    \n",
    "df['当月网购类应用使用次数'] = np.where(df['当月网购类应用使用次数']>10000, 10000, df['当月网购类应用使用次数'])\n",
    "\n",
    "df['当月金融理财类应用使用总次数'] = np.where(df['当月金融理财类应用使用总次数']>10000, 10000, df['当月金融理财类应用使用总次数'])\n",
    "\n",
    "df['用户当月账户余额（元）'] = np.where(df['用户当月账户余额（元）']>2000, \n",
    "                           df['用户当月账户余额（元）']/10, df['用户当月账户余额（元）'])\n",
    "                               # df['用户网龄（年）'] = df['用户网龄（月）'].apply(bins)\n",
    "# df.loc[df['用户话费敏感度']==0, '用户话费敏感度'] = df['用户话费敏感度'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['信用分']\n",
    "data = pd.concat([train_df.drop(columns=['信用分']), test_df], axis=0, ignore_index=True)\n",
    "data = generate_feature(data)\n",
    "train = data.loc[:49999, :]\n",
    "test = data.loc[50000:, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_x = train.loc[over_sample, :]\n",
    "sample_y = target[over_sample]\n",
    "train = pd.concat([train, sample_x], axis=0, ignore_index=True)\n",
    "target = pd.concat([target, sample_y], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['用户编码']\n",
    "X_train = train.drop(columns=drop_columns).values\n",
    "y_train = target.values\n",
    "X_test = test.drop(columns=drop_columns).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param = {'num_leaves': 30,\n",
    "         'objective':'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.008,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 0.15,\n",
    "         \"lambda_l2\": 0.04,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param = {'num_leaves': 35,\n",
    "         'objective':'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.004,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 0.15,\n",
    "         \"lambda_l2\": 0.05,\n",
    "         \"verbosity\": -1}\n",
    " 94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "阴差阳错我用的都是mse,只是用了不同的随机种子"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param1 = {'num_leaves': 40,\n",
    "         'objective':'regression_l2',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 5,\n",
    "         \"lambda_l2\": 1,\n",
    "         \"verbosity\": -1}\n",
    "param2 = {'num_leaves': 40,\n",
    "         'objective':'regression_l1',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 5,\n",
    "         \"lambda_l2\": 1,\n",
    "         \"verbosity\": -1}\n",
    "valid = []\n",
    "res = []\n",
    "best_params = {}\n",
    "for seed in [2018,2019]:\n",
    "    print('fire!!!!!')\n",
    "    print('*'*50)\n",
    "    start = time.time()\n",
    "    clf = my_lgb(folds=5, seed=seed)\n",
    "    #　_best_params = clf.optimize_lgb()\n",
    "    clf.inference_folds(X_train, y_train, X_test, param1)\n",
    "    print('*'*25)\n",
    "    valid.append(clf.oof)\n",
    "    res.append(clf.results)\n",
    "    clf_ = my_lgb(folds=5, seed=seed)\n",
    "    clf_.inference_folds(X_train, y_train, X_test, param2)\n",
    "    print('*'*25)\n",
    "    valid.append(clf_.oof)\n",
    "    res.append(clf.results)\n",
    "    print('seed:{},training spend {}s'.format(seed, time.time()-start))\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 40,\n",
    "         'objective':'regression_l2',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 5,\n",
    "         \"lambda_l2\": 0,\n",
    "         \"verbosity\": -1}\n",
    "clf = my_lgb(folds=5, seed=2018)\n",
    "clf.inference_folds(X_train, y_train, X_test, param)\n",
    "mse_2018 = clf.oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 35,\n",
    "         'objective':'regression_l2',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 5,\n",
    "         \"lambda_l2\": 0,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "clf_mse = my_lgb(folds=5, seed=2019)\n",
    "clf_mse.inference_folds(X_train, y_train, X_test, param)\n",
    "mse_2019 = clf_mse.oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.502\n",
    "q = 0.50\n",
    "results = mse_2018*p+ mse_2019*q \n",
    "print(score(results, y_train))\n",
    "res = clf.results*p + clf_mse.results*q\n",
    "# submit(model_name='model_V2_bad', predictions=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'objective':'regression_l1',\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 5,\n",
    "         \"lambda_l2\": 1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "clf_mae = my_lgb(folds=5, seed=2018)\n",
    "clf_mae.inference_folds(X_train, y_train, X_test, param)\n",
    "mae_2018 = clf_mae.oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.06398976\n",
    "clf_mae.submit(output_name = 'model_V1_mae_2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'objective':'regression_l1',\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 5,\n",
    "         \"lambda_l2\": 1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "clf_mae_ = my_lgb(folds=5, seed=2019)\n",
    "clf_mae_.inference_folds(X_train, y_train, X_test, param)\n",
    "mae_2019 = clf_mae_.oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.06399214\n",
    "clf_mae_.submit(output_name = 'model_V1_mae_2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param = {'num_leaves': 35,\n",
    "         'objective':'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.16,\n",
    "         \"lambda_l2\": 0.1,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.25\n",
    "q = 0.25\n",
    "m = 0.251\n",
    "n = 0.25\n",
    "results = mse_2018*p+ mse_2019*q + mae_2018*m + mae_2019*n\n",
    "print(score(results, y_train))\n",
    "res = clf.results*p + clf_mse.results*q + clf_mae.results*m + clf_mae_.results*n\n",
    "submit(model_name='model_V2_bad', predictions=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = mae_2018 - y_train\n",
    "submit(model_name='resdiual_mae', predictions=residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_columns = drop_columns.remove('信用分')\n",
    "col = train.drop(columns=drop_columns).columns\n",
    "f = clf_mae.importance_feature(col)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(residual>100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['用户网龄（月）', '当月通话交往圈人数', '用户年龄', \n",
    "       '用户账单当月总费用（元）', '用户近6个月平均消费值（元）', '当月金融理财类应用使用总次数', '当月视频播放类应用使用次数',\n",
    "       '当月网购类应用使用次数', '用户当月账户余额（元）', '近三个月月均商场出现次数',\n",
    "       '当月旅游资讯类应用使用次数', '缴费用户最近一次缴费金额（元）', '信用分']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[residual > 100,feature].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[23379, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
