{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from model_zoo import my_lgb,my_xgb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train_dataset.csv')\n",
    "test_df = pd.read_csv('dataset/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature(df):\n",
    "    df['用户前五个月平均消费值（元）'] = (df['用户近6个月平均消费值（元）']*6 - df['用户账单当月总费用（元）'])/5\n",
    "    \n",
    "    df['当月消费值较前五个月平均消费值'] = df['用户账单当月总费用（元）'] - df['用户前五个月平均消费值（元）']\n",
    "    \n",
    "    app_col = []\n",
    "    for col in df.columns:\n",
    "        if '应用' in col:\n",
    "            app_col.append(col)\n",
    "    df['各类应用使用总和'] = df[app_col].sum(axis=1)\n",
    "    \n",
    "    # count 特征\n",
    "    df['用户近6个月平均消费值（元）'] = np.rint(df['用户近6个月平均消费值（元）'])\n",
    "    feature = ['用户网龄（月）','用户近6个月平均消费值（元）']\n",
    "    for f in feature:\n",
    "        new_feature = f + '_count'\n",
    "        temp = df.groupby(f).size().reset_index().rename(columns={0: new_feature})\n",
    "        df = df.merge(temp, 'left', on=f)\n",
    "\n",
    "    # df['人均消费'] = df['用户账单当月总费用（元）']/(df['当月通话交往圈人数'] + 1)\n",
    "    \n",
    "    # df['交通消费'] = df['当月火车类应用使用次数'] + df['当月飞机类应用使用次数']\n",
    "    \n",
    "    df['当月视频播放类应用使用次数'] = np.where(df['当月视频播放类应用使用次数']>30000, 30000, df['当月视频播放类应用使用次数'])\n",
    "    \n",
    "    df['当月网购类应用使用次数'] = np.where(df['当月网购类应用使用次数']>10000, 10000, df['当月网购类应用使用次数'])\n",
    "    \n",
    "    df['当月金融理财类应用使用总次数'] = np.where(df['当月金融理财类应用使用总次数']>10000, 10000, df['当月金融理财类应用使用总次数'])\n",
    "    \n",
    "    df['当月网购类应用使用次数' + '百分比'] = df['当月网购类应用使用次数']/(df['各类应用使用总和'] + 1)\n",
    "    \n",
    "    df['用户当月账户余额（元）'] = np.where(df['用户当月账户余额（元）']>2000, \n",
    "                                df['用户当月账户余额（元）']/10, df['用户当月账户余额（元）'])\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pre, truth):\n",
    "    return 1 / (MAE(pre, truth) + 1)\n",
    "\n",
    "def MAE(pre, truth):\n",
    "    return abs((np.rint(pre) - truth)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = generate_feature(train_df)\n",
    "test_df = generate_feature(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['用户编码','信用分', '是否大学生客户','各类应用使用总和',\n",
    "                '用户实名制是否通过核实', '当月是否到过福州山姆会员店', \n",
    "                '当月是否逛过福州仓山万达']\n",
    "\n",
    "X_train = train_df.drop(columns=drop_columns).values\n",
    "y_train = train_df['信用分'].values\n",
    "drop_columns.remove('信用分')\n",
    "X_test = test_df.drop(columns=drop_columns).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, bins = pd.cut(y_train, 30, retbins=True, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 150,\n",
    "         'objective':'multiclass',\n",
    "         \"num_class\":np.unique(y_train).size,\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.5,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.5,\n",
    "         \"metric\": 'multi_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"lambda_l2\": 0.1,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's multi_logloss: 1.77099\tvalid_1's multi_logloss: 2.32413\n",
      "[400]\ttraining's multi_logloss: 1.36165\tvalid_1's multi_logloss: 2.21136\n",
      "[600]\ttraining's multi_logloss: 1.10467\tvalid_1's multi_logloss: 2.17589\n",
      "[800]\ttraining's multi_logloss: 0.919312\tvalid_1's multi_logloss: 2.1692\n",
      "Early stopping, best iteration is:\n",
      "[792]\ttraining's multi_logloss: 0.9258\tvalid_1's multi_logloss: 2.16917\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's multi_logloss: 1.7742\tvalid_1's multi_logloss: 2.32261\n",
      "[400]\ttraining's multi_logloss: 1.36513\tvalid_1's multi_logloss: 2.20433\n",
      "[600]\ttraining's multi_logloss: 1.10786\tvalid_1's multi_logloss: 2.16505\n",
      "[800]\ttraining's multi_logloss: 0.922256\tvalid_1's multi_logloss: 2.15594\n",
      "Early stopping, best iteration is:\n",
      "[826]\ttraining's multi_logloss: 0.901686\tvalid_1's multi_logloss: 2.15562\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's multi_logloss: 1.77455\tvalid_1's multi_logloss: 2.31754\n",
      "[400]\ttraining's multi_logloss: 1.36474\tvalid_1's multi_logloss: 2.20152\n",
      "[600]\ttraining's multi_logloss: 1.10734\tvalid_1's multi_logloss: 2.1641\n",
      "[800]\ttraining's multi_logloss: 0.921298\tvalid_1's multi_logloss: 2.15494\n",
      "Early stopping, best iteration is:\n",
      "[813]\ttraining's multi_logloss: 0.910941\tvalid_1's multi_logloss: 2.15481\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's multi_logloss: 1.77243\tvalid_1's multi_logloss: 2.32231\n",
      "[400]\ttraining's multi_logloss: 1.36217\tvalid_1's multi_logloss: 2.20732\n",
      "[600]\ttraining's multi_logloss: 1.10472\tvalid_1's multi_logloss: 2.16986\n",
      "[800]\ttraining's multi_logloss: 0.918884\tvalid_1's multi_logloss: 2.16223\n",
      "Early stopping, best iteration is:\n",
      "[799]\ttraining's multi_logloss: 0.919681\tvalid_1's multi_logloss: 2.16221\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's multi_logloss: 1.77529\tvalid_1's multi_logloss: 2.31114\n",
      "[400]\ttraining's multi_logloss: 1.3649\tvalid_1's multi_logloss: 2.195\n",
      "[600]\ttraining's multi_logloss: 1.10737\tvalid_1's multi_logloss: 2.15648\n",
      "[800]\ttraining's multi_logloss: 0.921501\tvalid_1's multi_logloss: 2.14675\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's multi_logloss: 0.919918\tvalid_1's multi_logloss: 2.1467\n",
      "score: 0.05630643, MAE: 16.75996\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof = np.zeros(X_train.shape[0])\n",
    "predictions = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=200,\n",
    "                    early_stopping_rounds=100)\n",
    "    oof[val_idx] = np.argmax(clf.predict(X_train[val_idx], num_iteration=clf.best_iteration), axis=1) * 9.9 + 421.7\n",
    "\n",
    "    predictions += (np.argmax(clf.predict(X_test, num_iteration=clf.best_iteration), axis=1) * 9.9 + 421.7) / folds.n_splits\n",
    "\n",
    "\n",
    "results = np.rint(predictions).astype('int64')\n",
    "\n",
    "print(\"score: {:.8f}, MAE: {}\".format(score(oof, train_df['信用分']), MAE(oof, train_df['信用分'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.05731040, MAE: 16.44884\n"
     ]
    }
   ],
   "source": [
    "print(\"score: {:.8f}, MAE: {}\".format(score(oof, train_df['信用分']), MAE(oof, train_df['信用分'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
